{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b38be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install great_expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f72a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyright: reportPrivateImportUsage=false\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import great_expectations as gx\n",
    "\n",
    "# ======================================================\n",
    "# Google Drive\n",
    "# ======================================================\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "# ======================================================\n",
    "# Paths (Drive)\n",
    "# ======================================================\n",
    "BASE = Path(\"/content/drive/MyDrive/dadosfera\")\n",
    "\n",
    "RAW_DIR = BASE / \"cdm_bronze\"\n",
    "REPORT_DIR = BASE / \"reports\" / \"data_quality_precleaning\"\n",
    "REPORT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"CDM Bronze:\", RAW_DIR)\n",
    "print(\"Reports:\", REPORT_DIR)\n",
    "\n",
    "DATASETS = {\n",
    "    \"orders\": \"order.csv\",\n",
    "    \"order_items\": \"order_item.csv\",\n",
    "    \"payments\": \"payment.csv\",\n",
    "    \"reviews\": \"review.csv\",\n",
    "    \"customers\": \"customer.csv\",\n",
    "    \"sellers\": \"seller.csv\",\n",
    "    \"products\": \"product.csv\",\n",
    "    \"geolocation\": \"geo_zip.csv\",\n",
    "}\n",
    "\n",
    "# ======================================================\n",
    "# IO utils\n",
    "# ======================================================\n",
    "def load_csv(filename: str) -> pd.DataFrame:\n",
    "    path = RAW_DIR / filename\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"CSV não encontrado: {path}\")\n",
    "    return pd.read_csv(path, low_memory=False)\n",
    "\n",
    "\n",
    "def save_json(obj: Any, path: Path):\n",
    "    def _default(o):\n",
    "        if hasattr(o, \"to_json_dict\"):\n",
    "            return o.to_json_dict()\n",
    "        if hasattr(o, \"dict\"):\n",
    "            return o.dict()\n",
    "        if hasattr(o, \"__dict__\"):\n",
    "            return o.__dict__\n",
    "        return str(o)\n",
    "\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, indent=2, ensure_ascii=False, default=_default)\n",
    "\n",
    "\n",
    "def write_summary_md(summary_rows: List[Dict[str, Any]], path: Path):\n",
    "    lines = []\n",
    "    lines.append(\"# Relatório de Qualidade de Dados – Great Expectations (CDM Bronze)\\n\")\n",
    "    lines.append(\n",
    "        \"Validações executadas sobre os dados da camada CDM Bronze, antes do processo de limpeza e normalização (pre-cleaning).\\n\"\n",
    "    )\n",
    "    lines.append(\"| Dataset | Sucesso | % Sucesso | Expectations | OK | Falhas |\")\n",
    "    lines.append(\"|---|---:|---:|---:|---:|---:|\")\n",
    "    for r in summary_rows:\n",
    "        lines.append(\n",
    "            f\"| {r['dataset']} | {'Ok' if r['success'] else 'Not Okay'} | {r['success_percent']}% | \"\n",
    "            f\"{r['evaluated_expectations']} | {r['successful_expectations']} | {r['unsuccessful_expectations']} |\"\n",
    "        )\n",
    "    path.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# Great Expectations\n",
    "# ======================================================\n",
    "def get_or_create_pandas_datasource(context, name: str = \"pandas\"):\n",
    "    try:\n",
    "        return context.data_sources.get(name)\n",
    "    except Exception:\n",
    "        return context.data_sources.add_pandas(name)\n",
    "\n",
    "\n",
    "def make_batch_from_df(context, df: pd.DataFrame, dataset_name: str):\n",
    "    datasource = get_or_create_pandas_datasource(context, \"pandas\")\n",
    "    asset_name = f\"{dataset_name}_asset\"\n",
    "    batch_def_name = \"whole_dataframe\"\n",
    "\n",
    "    try:\n",
    "        asset = datasource.get_asset(asset_name)\n",
    "    except Exception:\n",
    "        asset = datasource.add_dataframe_asset(name=asset_name)\n",
    "\n",
    "    try:\n",
    "        batch_def = asset.get_batch_definition(batch_def_name)\n",
    "    except Exception:\n",
    "        batch_def = asset.add_batch_definition_whole_dataframe(name=batch_def_name)\n",
    "\n",
    "    batch = batch_def.get_batch(batch_parameters={\"dataframe\": df})\n",
    "    return batch\n",
    "\n",
    "\n",
    "def run_expectations(batch, expectations: List[Any]) -> Dict[str, Any]:\n",
    "    results = []\n",
    "    ok = 0\n",
    "\n",
    "    for exp in expectations:\n",
    "        r = batch.validate(exp)\n",
    "\n",
    "        if hasattr(r, \"to_json_dict\"):\n",
    "            r_json = r.to_json_dict()\n",
    "        elif isinstance(r, dict):\n",
    "            r_json = r\n",
    "        else:\n",
    "            r_json = {\"success\": bool(getattr(r, \"success\", False)), \"result\": str(r)}\n",
    "\n",
    "        if bool(r_json.get(\"success\", False)):\n",
    "            ok += 1\n",
    "\n",
    "        results.append(r_json)\n",
    "\n",
    "    total = len(expectations)\n",
    "    fail = total - ok\n",
    "    success_percent = round((ok / total) * 100, 2) if total else 0.0\n",
    "\n",
    "    return {\n",
    "        \"success\": fail == 0,\n",
    "        \"statistics\": {\n",
    "            \"evaluated_expectations\": total,\n",
    "            \"successful_expectations\": ok,\n",
    "            \"unsuccessful_expectations\": fail,\n",
    "            \"success_percent\": success_percent,\n",
    "        },\n",
    "        \"expectation_results\": results,\n",
    "    }\n",
    "\n",
    "\n",
    "def summarize_result(dataset_name: str, result_json: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    stats = result_json.get(\"statistics\", {})\n",
    "    return {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"success\": bool(result_json.get(\"success\", False)),\n",
    "        \"success_percent\": round(float(stats.get(\"success_percent\", 0.0)), 2),\n",
    "        \"evaluated_expectations\": int(stats.get(\"evaluated_expectations\", 0)),\n",
    "        \"successful_expectations\": int(stats.get(\"successful_expectations\", 0)),\n",
    "        \"unsuccessful_expectations\": int(stats.get(\"unsuccessful_expectations\", 0)),\n",
    "    }\n",
    "\n",
    "# ======================================================\n",
    "# Expectations (as mesmas – CDM Bronze)\n",
    "# ======================================================\n",
    "def expectations_orders():\n",
    "    return [\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"order_id\"),\n",
    "        gx.expectations.ExpectColumnValuesToBeUnique(column=\"order_id\"),\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"customer_id\"),\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"created_at\"),\n",
    "        gx.expectations.ExpectColumnValuesToBeInSet(\n",
    "            column=\"status\",\n",
    "            value_set=[\"delivered\", \"shipped\", \"canceled\", \"invoiced\", \"processing\", \"unavailable\", \"approved\"],\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "\n",
    "def expectations_order_items():\n",
    "    return [\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"order_id\"),\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"order_item_id\"),\n",
    "        gx.expectations.ExpectCompoundColumnsToBeUnique(column_list=[\"order_id\", \"order_item_id\"]),\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"product_id\"),\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"seller_id\"),\n",
    "        gx.expectations.ExpectColumnValuesToBeBetween(column=\"item_price\", min_value=0),\n",
    "        gx.expectations.ExpectColumnValuesToBeBetween(column=\"freight_value\", min_value=0),\n",
    "    ]\n",
    "\n",
    "\n",
    "def expectations_payments():\n",
    "    return [\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"order_id\"),\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"payment_seq\"),\n",
    "        gx.expectations.ExpectCompoundColumnsToBeUnique(column_list=[\"order_id\", \"payment_seq\"]),\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"payment_type\", mostly=0.98),\n",
    "        gx.expectations.ExpectColumnValuesToBeBetween(column=\"installments\", min_value=0, mostly=0.98),\n",
    "        gx.expectations.ExpectColumnValuesToBeBetween(column=\"payment_value\", min_value=0),\n",
    "    ]\n",
    "\n",
    "\n",
    "def expectations_reviews():\n",
    "    return [\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"order_id\", mostly=0.98),\n",
    "        gx.expectations.ExpectColumnValuesToBeBetween(column=\"score\", min_value=1, max_value=5, mostly=0.95),\n",
    "    ]\n",
    "\n",
    "\n",
    "def expectations_customers():\n",
    "    return [\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"customer_id\"),\n",
    "        gx.expectations.ExpectColumnValuesToBeUnique(column=\"customer_id\"),\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"state\", mostly=0.98),\n",
    "        gx.expectations.ExpectColumnValueLengthsToBeBetween(column=\"state\", min_value=2, max_value=2, mostly=0.98),\n",
    "    ]\n",
    "\n",
    "\n",
    "def expectations_sellers():\n",
    "    return [\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"seller_id\"),\n",
    "        gx.expectations.ExpectColumnValuesToBeUnique(column=\"seller_id\"),\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"state\", mostly=0.98),\n",
    "        gx.expectations.ExpectColumnValueLengthsToBeBetween(column=\"state\", min_value=2, max_value=2, mostly=0.98),\n",
    "    ]\n",
    "\n",
    "\n",
    "def expectations_products():\n",
    "    exps = [\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"product_id\"),\n",
    "        gx.expectations.ExpectColumnValuesToBeUnique(column=\"product_id\"),\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"category_pt\", mostly=0.95),\n",
    "    ]\n",
    "    for col in [\"weight_g\", \"length_cm\", \"height_cm\", \"width_cm\"]:\n",
    "        exps.append(gx.expectations.ExpectColumnValuesToBeBetween(column=col, min_value=0, mostly=0.98))\n",
    "    return exps\n",
    "\n",
    "\n",
    "def expectations_geolocation():\n",
    "    return [\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"zip_prefix\"),\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"lat_avg\"),\n",
    "        gx.expectations.ExpectColumnValuesToNotBeNull(column=\"lng_avg\"),\n",
    "        gx.expectations.ExpectColumnValuesToBeBetween(column=\"lat_avg\", min_value=-35, max_value=6, mostly=0.98),\n",
    "        gx.expectations.ExpectColumnValuesToBeBetween(column=\"lng_avg\", min_value=-75, max_value=-30, mostly=0.98),\n",
    "    ]\n",
    "\n",
    "# ======================================================\n",
    "# Main\n",
    "# ======================================================\n",
    "if __name__ == \"__main__\":\n",
    "    context = gx.get_context()\n",
    "\n",
    "    jobs = [\n",
    "        (\"orders\", DATASETS[\"orders\"], expectations_orders),\n",
    "        (\"order_items\", DATASETS[\"order_items\"], expectations_order_items),\n",
    "        (\"payments\", DATASETS[\"payments\"], expectations_payments),\n",
    "        (\"reviews\", DATASETS[\"reviews\"], expectations_reviews),\n",
    "        (\"customers\", DATASETS[\"customers\"], expectations_customers),\n",
    "        (\"sellers\", DATASETS[\"sellers\"], expectations_sellers),\n",
    "        (\"products\", DATASETS[\"products\"], expectations_products),\n",
    "        (\"geolocation\", DATASETS[\"geolocation\"], expectations_geolocation),\n",
    "    ]\n",
    "\n",
    "    full_results = {}\n",
    "    summary_rows = []\n",
    "\n",
    "    for dataset_name, filename, exp_factory in jobs:\n",
    "        print(f\"Validando: {dataset_name}\")\n",
    "        df = load_csv(filename)\n",
    "\n",
    "        batch = make_batch_from_df(context, df, dataset_name)\n",
    "        result = run_expectations(batch, exp_factory())\n",
    "\n",
    "        full_results[dataset_name] = result\n",
    "        summary_rows.append(summarize_result(dataset_name, result))\n",
    "\n",
    "    full_json = REPORT_DIR / \"ge_cdm_bronze_full_results.json\"\n",
    "    summary_json = REPORT_DIR / \"ge_cdm_bronze_summary.json\"\n",
    "    summary_md = REPORT_DIR / \"ge_cdm_bronze_summary.md\"\n",
    "\n",
    "    save_json(full_results, full_json)\n",
    "    save_json(summary_rows, summary_json)\n",
    "    write_summary_md(summary_rows, summary_md)\n",
    "\n",
    "    print(\"\\nRelatórios gerados:\")\n",
    "    print(\"-\", full_json)\n",
    "    print(\"-\", summary_json)\n",
    "    print(\"-\", summary_md)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
